{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Install and import libraries"
      ],
      "metadata": {
        "id": "U_oLKNcyNgLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --upgrade openai\n",
        "!pip install pywer"
      ],
      "metadata": {
        "id": "-XIxvrw0NfgG"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pywer\n",
        "import numpy as np\n",
        "\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics import f1_score\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "xJeLZ64wNqRL"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Init gpt-client\n",
        "GPT_API_KEY = \"YOUR_GPT_API_KEY\"\n",
        "client = OpenAI(api_key=GPT_API_KEY)"
      ],
      "metadata": {
        "id": "SbGh2Ud8ixFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Helper functions"
      ],
      "metadata": {
        "id": "SapXmrI_ZuBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title the prompt function\n",
        "\n",
        "def get_prompts(system_content, two_shots_list):\n",
        "  shots = {\n",
        "      \"zero-shot\": [\n",
        "                {\n",
        "                  \"role\": \"system\",\n",
        "                  \"content\": system_content\n",
        "                }\n",
        "            ],\n",
        "      \"two-shot\": [\n",
        "                {\n",
        "                  \"role\": \"system\",\n",
        "                  \"content\": system_content\n",
        "                }\n",
        "            ]\n",
        "  }\n",
        "  for (role, content) in two_shots_list:\n",
        "    shots['two-shot'].append(\n",
        "        {\n",
        "          \"role\": role,\n",
        "          \"content\": content\n",
        "        }\n",
        "    )\n",
        "  return shots"
      ],
      "metadata": {
        "id": "s79pm4TFHSYm"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title gpt predictions\n",
        "def get_gpt_response(prompt_dict, gpt_model, x, y_true):\n",
        "  res_dict = {\"zero-shot\": [], \"two-shot\": []}\n",
        "\n",
        "  for shot in prompt_dict:\n",
        "    for i, instance in enumerate(x):\n",
        "        messages = prompt_dict[shot].copy()\n",
        "        messages.append({\"role\": \"user\", \"content\": instance})\n",
        "        response = client.chat.completions.create(\n",
        "          model=gpt_model,\n",
        "          messages=messages,\n",
        "          temperature=0.2,\n",
        "          seed=42,\n",
        "          top_p=1,\n",
        "          frequency_penalty=0,\n",
        "          presence_penalty=0,\n",
        "          logprobs=True\n",
        "        )\n",
        "        y_pred = response.choices[0].message.content\n",
        "        res_dict[shot].append({\"x\": instance, \"y_true\": y_true.iloc[i], \"y_pred\": y_pred})\n",
        "    res_dict[shot] = pd.DataFrame(res_dict[shot])\n",
        "\n",
        "  df_pred = pd.merge(res_dict['zero-shot'], res_dict['two-shot'], on=[\"x\", \"y_true\"], how=\"inner\")\n",
        "  df_pred.columns = [\"x\", \"y_true\", \"y_pred_zero_shot\", \"y_pred_two_shot\"]\n",
        "  return df_pred"
      ],
      "metadata": {
        "id": "NYh4Gh5uLnGA"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GEC"
      ],
      "metadata": {
        "id": "Gail_mSyYM2z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Rx_nFK3sYAlY"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!gdown 1-f-Rpz9AV-svNPD5hFofKSgMWwQ49skD\n",
        "df = pd.read_csv(\"korre.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predictions\n",
        "x, y_true = df.original_text, df.corrected_text\n",
        "system_content = \"Given a sentence, correct it for grammatical errors, including punctuation, spelling, and morphology of word. Generate only the corrected text.\"\n",
        "two_shots_list = [\n",
        "    ('user', \"Δεν ήθελε να θεωρηθεί προκατειλημένος και για αυτό δε συνέχισε τη συνεργασία περεταίρω.\"),\n",
        "    ('assistant', \"Δεν ήθελε να θεωρηθεί προκατειλημμένος και για αυτό δε συνέχισε τη συνεργασία περαιτέρω.\"),\n",
        "    ('user', \"Το περιθώριο των κερδών τους δεν αλλάζουν εύκολα.\"),\n",
        "    ('assistant', \"Το περιθώριο των κερδών τους δεν αλλάζει εύκολα.\")\n",
        "]\n",
        "prompt_dict = get_prompts(system_content, two_shots_list)\n",
        "\n",
        "df_gpt_3_5 = get_gpt_response(prompt_dict, \"gpt-3.5-turbo\", x, y_true)\n",
        "df_gpt_4o = get_gpt_response(prompt_dict, \"gpt-4o\", x, y_true)"
      ],
      "metadata": {
        "id": "v0pp3fKAi4aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Results\n",
        "print(f\"gpt-model \\t shot \\t\\t cer \\t\\t wer\")\n",
        "cer = df_gpt_3_5.apply(lambda row: pywer.cer([row.y_true], [row.y_pred_zero_shot]),1).agg(['mean', 'sem'])\n",
        "wer = df_gpt_3_5.apply(lambda row: pywer.wer([row.y_true], [row.y_pred_zero_shot]),1).agg(['mean', 'sem'])\n",
        "print(f\"3.5 \\t\\t zero-shot \\t {cer['mean']:.2f}±{cer['sem']:.2f} \\t {wer['mean']:.2f}±{wer['sem']:.2f}\")\n",
        "cer = df_gpt_3_5.apply(lambda row: pywer.cer([row.y_true], [row.y_pred_two_shot]),1).agg(['mean', 'sem'])\n",
        "wer = df_gpt_3_5.apply(lambda row: pywer.wer([row.y_true], [row.y_pred_two_shot]),1).agg(['mean', 'sem'])\n",
        "print(f\"3.5 \\t\\t two-shot \\t {cer['mean']:.2f}±{cer['sem']:.2f} \\t {wer['mean']:.2f}±{wer['sem']:.2f}\")\n",
        "cer = df_gpt_4o.apply(lambda row: pywer.cer([row.y_true], [row.y_pred_zero_shot]),1).agg(['mean', 'sem'])\n",
        "wer = df_gpt_4o.apply(lambda row: pywer.wer([row.y_true], [row.y_pred_zero_shot]),1).agg(['mean', 'sem'])\n",
        "print(f\"4o \\t\\t zero-shot \\t {cer['mean']:.2f}±{cer['sem']:.2f} \\t {wer['mean']:.2f}±{wer['sem']:.2f}\")\n",
        "cer = df_gpt_4o.apply(lambda row: pywer.cer([row.y_true], [row.y_pred_two_shot]),1).agg(['mean', 'sem'])\n",
        "wer = df_gpt_4o.apply(lambda row: pywer.wer([row.y_true], [row.y_pred_two_shot]),1).agg(['mean', 'sem'])\n",
        "print(f\"4o \\t\\t two-shot \\t {cer['mean']:.2f}±{cer['sem']:.2f} \\t {wer['mean']:.2f}±{wer['sem']:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1fMEMpXOOuy",
        "outputId": "d315f3d1-4445-47ac-a624-fe0263d92762"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-model \t shot \t\t cer \t\t wer\n",
            "3.5 \t\t zero-shot \t 2.99±0.39 \t 8.24±0.66\n",
            "3.5 \t\t two-shot \t 2.59±0.38 \t 7.22±0.65\n",
            "4o \t\t zero-shot \t 1.79±0.20 \t 6.92±0.48\n",
            "4o \t\t two-shot \t 2.06±0.22 \t 7.49±0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Toxicity"
      ],
      "metadata": {
        "id": "WiAT-skK4Vvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!gdown 1-qZlF8hHp2VeXi0irhGLZhUgANIsPku_\n",
        "!gdown 1-xZfiYx0bNmYF851Ulquh2TyXOFS8341\n",
        "df_test = pd.read_csv(\"zampieri_test.csv\")"
      ],
      "metadata": {
        "id": "GYPYLeBy4wwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predictions\n",
        "\n",
        "x, y_true = df_test.text, df_test.subtask_a\n",
        "system_content = \"Given a tweet, determine if it contains offensive language. If the tweet is offensive, output a 1. If the text is not offensive, output a 0.\"\n",
        "# Examples taken from training set\n",
        "two_shots_list = [\n",
        "    ('user', \"Το #gntmgr κρατα τρεις μήνες μόνο για να μη φαίνεται η κοιλιά αν γκαστρωθεί κάποια κοπέλα.\"),\n",
        "    ('assistant', \"1\"),\n",
        "    ('user', \"Κανονικά ο τύπος θα έπρεπε να ντρέπεται μόνο και μόνο που συμμετέχει στο #poweroflovegr όχι που το βλέπει #giatinparea\"),\n",
        "    ('assistant', \"0\")\n",
        "]\n",
        "prompt_dict = get_prompts(system_content, two_shots_list)\n",
        "\n",
        "df_gpt_3_5 = get_gpt_response(prompt_dict, \"gpt-3.5-turbo\", x, y_true)\n",
        "df_gpt_4o = get_gpt_response(prompt_dict, \"gpt-4o\", x, y_true)"
      ],
      "metadata": {
        "id": "BZ5oPPRjWi40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Results\n",
        "gpt_3_5_s0, gpt_3_5_s2, gpt_4o_s0, gpt_4o_s2 = [], [], [], []\n",
        "for i in range(10):\n",
        "  gpt_3_5_test_sample = df_gpt_3_5.sample(500)\n",
        "  gpt_3_5_s0.append(f1_score(gpt_3_5_test_sample.y_true, gpt_3_5_test_sample.y_pred_zero_shot, average='macro'))\n",
        "  gpt_3_5_s2.append(f1_score(gpt_3_5_test_sample.y_true, gpt_3_5_test_sample.y_pred_two_shot, average='macro'))\n",
        "\n",
        "  gpt_4o_test_sample = df_gpt_4o.sample(500)\n",
        "  gpt_4o_s0.append(f1_score(gpt_4o_test_sample.y_true, gpt_4o_test_sample.y_pred_zero_shot, average='macro'))\n",
        "  gpt_4o_s2.append(f1_score(gpt_4o_test_sample.y_true, gpt_4o_test_sample.y_pred_two_shot, average='macro'))\n",
        "\n",
        "\n",
        "print(f\"gpt-model \\t shot \\t\\t F1\")\n",
        "f1 = pd.Series(gpt_3_5_s0).agg(['mean', 'sem'])\n",
        "print(f\"3.5 \\t\\t zero-shot \\t {f1['mean']:.2f}±{f1['sem']:.3f}\")\n",
        "f1 = pd.Series(gpt_3_5_s2).agg(['mean', 'sem'])\n",
        "print(f\"3.5 \\t\\t two-shot \\t {f1['mean']:.2f}±{f1['sem']:.3f}\")\n",
        "f1 = pd.Series(gpt_4o_s0).agg(['mean', 'sem'])\n",
        "print(f\"4o \\t\\t zero-shot \\t {f1['mean']:.2f}±{f1['sem']:.3f}\")\n",
        "f1 = pd.Series(gpt_4o_s2).agg(['mean', 'sem'])\n",
        "print(f\"4o \\t\\t two-shot \\t {f1['mean']:.2f}±{f1['sem']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq7bnVmLYOG0",
        "outputId": "d5eded16-f588-4659-a8b9-f32a681445b2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-model \t shot \t\t F1\n",
            "3.5 \t\t zero-shot \t 0.68±0.010\n",
            "3.5 \t\t two-shot \t 0.55±0.008\n",
            "4o \t\t zero-shot \t 0.74±0.008\n",
            "4o \t\t two-shot \t 0.66±0.008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MT"
      ],
      "metadata": {
        "id": "bkHsQMJsSaEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!gdown 1-m4soJYv2F-YgjXp1Wn5aBXXoORnjC0C\n",
        "df = pd.read_csv(\"prokopidis.csv\")\n",
        "# Get the first 17 languages to evaluate\n",
        "lang_cols = [col for col in df.columns if 'score' not in col][:18]\n",
        "df = df[lang_cols]"
      ],
      "metadata": {
        "id": "UMEm4jd-SdNQ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predictions\n",
        "\n",
        "target_langs = list(df.columns[1:])\n",
        "\n",
        "res = {}\n",
        "for lang in target_langs:\n",
        "  lan_all_df = df[df[lang].notna()]\n",
        "  if lang == 'English':\n",
        "    lang_df = df[df[lang].notna()].loc[:, ['Greek', lang]]\n",
        "  else:\n",
        "    lang_df = df[df[lang].notna()].loc[:, ['Greek', 'English', lang]]\n",
        "\n",
        "  # Train-test split. In test set add only instances that have the\n",
        "  # English translation.\n",
        "  null_mask = lang_df['English'].isna()\n",
        "  without_en_df = lang_df[null_mask]\n",
        "  with_en_df = lang_df[~null_mask]\n",
        "  train_df, test_df = train_test_split(with_en_df, test_size=50, random_state=42)\n",
        "  train_df = pd.concat([train_df, without_en_df])\n",
        "\n",
        "  # Get a test sample of 5 instances to evaluate\n",
        "  sample_test_df = test_df.sample(5, random_state=42)\n",
        "  x, y_true = sample_test_df[\"Greek\"], sample_test_df[lang]\n",
        "\n",
        "  # Get two samples from training set to build the two-shot examples\n",
        "  train_sample_df = df.sample(2, random_state=42)\n",
        "  system_content = f\"Given a piece of text in Greek, translate it to {lang}. Generate only the translated text.\"\n",
        "  two_shots_list = [\n",
        "      ('user', train_sample_df[\"Greek\"].iloc[0]),\n",
        "      ('assistant', train_sample_df[lang].iloc[0]),\n",
        "      ('user', train_sample_df[\"Greek\"].iloc[1]),\n",
        "      ('assistant', train_sample_df[lang].iloc[1])\n",
        "  ]\n",
        "  prompt_dict = get_prompts(system_content, two_shots_list)\n",
        "\n",
        "  df_gpt_3_5 = get_gpt_response(prompt_dict, \"gpt-3.5-turbo\", x, y_true)\n",
        "  df_gpt_4o = get_gpt_response(prompt_dict, \"gpt-4o\", x, y_true)\n",
        "  res[lang] = [df_gpt_3_5, df_gpt_4o]"
      ],
      "metadata": {
        "id": "k736vya7T2_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Results per target language\n",
        "\n",
        "def calc_bleu_score(row, col):\n",
        "  ref = row.y_true\n",
        "  cand = row[col]\n",
        "  return corpus_bleu([[ref]], [cand], weights=(1.0,))\n",
        "\n",
        "print(\"\\t\\t\\t\\tBleu score\")\n",
        "print(\"\\t\\t gpt3.5 \\t\\t\\t gpt4o\")\n",
        "print(f\"lang \\t 0shot \\t\\t 2shot \\t\\t 0shot \\t\\t 2shot\\n\")\n",
        "bleu_dict = {}\n",
        "for lang in res:\n",
        "  gpt_3_5_bleu_0s = res[lang][0].apply(lambda row: calc_bleu_score(row, \"y_pred_zero_shot\"), axis=1).mean()\n",
        "  gpt_3_5_bleu_2s = res[lang][0].apply(lambda row: calc_bleu_score(row, \"y_pred_two_shot\"), axis=1).mean()\n",
        "  gpt_4o_bleu_0s = res[lang][1].apply(lambda row: calc_bleu_score(row, \"y_pred_zero_shot\"), axis=1).mean()\n",
        "  gpt_4o_bleu_2s = res[lang][1].apply(lambda row: calc_bleu_score(row, \"y_pred_two_shot\"), axis=1).mean()\n",
        "  print(f\"{lang[:5]} \\t {gpt_3_5_bleu_0s.mean():.2f}±{gpt_3_5_bleu_0s.std():.2f} \\t {gpt_3_5_bleu_2s.mean():.2f}±{gpt_3_5_bleu_2s.std():.2f} \\t {gpt_4o_bleu_0s.mean():.2f}±{gpt_4o_bleu_0s.std():.2f} \\t {gpt_4o_bleu_2s.mean():.2f}±{gpt_4o_bleu_2s.std():.2f}\")\n",
        "  bleu_dict[lang] = [gpt_3_5_bleu_0s.mean(), gpt_3_5_bleu_2s.mean(), gpt_4o_bleu_0s.mean(), gpt_4o_bleu_2s.mean()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ECYXx56l-ZI",
        "outputId": "0e8462f5-1411-433e-9e33-94ca5760b27a"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\t\tBleu score\n",
            "\t\t gpt3.5 \t\t\t gpt4o\n",
            "lang \t 0shot \t\t 2shot \t\t 0shot \t\t 2shot\n",
            "\n",
            "Engli \t 0.73±0.00 \t 0.77±0.00 \t 0.79±0.00 \t 0.79±0.00\n",
            "Esper \t 0.80±0.00 \t 0.78±0.00 \t 0.82±0.00 \t 0.80±0.00\n",
            "Farsi \t 0.81±0.00 \t 0.84±0.00 \t 0.79±0.00 \t 0.80±0.00\n",
            "Filip \t 0.66±0.00 \t 0.71±0.00 \t 0.68±0.00 \t 0.69±0.00\n",
            "Frenc \t 0.79±0.00 \t 0.77±0.00 \t 0.77±0.00 \t 0.77±0.00\n",
            "Hebre \t 0.67±0.00 \t 0.70±0.00 \t 0.60±0.00 \t 0.71±0.00\n",
            "Hindi \t 0.55±0.00 \t 0.57±0.00 \t 0.62±0.00 \t 0.58±0.00\n",
            "Hunga \t 0.72±0.00 \t 0.72±0.00 \t 0.73±0.00 \t 0.73±0.00\n",
            "Indon \t 0.79±0.00 \t 0.80±0.00 \t 0.79±0.00 \t 0.79±0.00\n",
            "Itali \t 0.75±0.00 \t 0.75±0.00 \t 0.77±0.00 \t 0.79±0.00\n",
            "Japan \t 0.24±0.00 \t 0.31±0.00 \t 0.31±0.00 \t 0.31±0.00\n",
            "Khmer \t 0.31±0.00 \t 0.32±0.00 \t 0.32±0.00 \t 0.34±0.00\n",
            "Korea \t 0.37±0.00 \t 0.40±0.00 \t 0.34±0.00 \t 0.35±0.00\n",
            "Maced \t 0.73±0.00 \t 0.71±0.00 \t 0.75±0.00 \t 0.75±0.00\n",
            "Malag \t 0.64±0.00 \t 0.68±0.00 \t 0.64±0.00 \t 0.65±0.00\n",
            "Burme \t 0.20±0.00 \t 0.20±0.00 \t 0.53±0.00 \t 0.55±0.00\n",
            "Dutch \t 0.77±0.00 \t 0.76±0.00 \t 0.78±0.00 \t 0.82±0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Results per language tier\n",
        "\n",
        "# Language tiers\n",
        "tiers_dict = {\n",
        "    \"English\": 1,\n",
        "    \"Esperanto\": 3,\n",
        "    \"Farsi\": 3,\n",
        "    \"Filipino\": 3,\n",
        "    'French': 1,\n",
        "    'Hebrew': 3,\n",
        "    'Hindi': 2,\n",
        "    'Hungarian': 3,\n",
        "    'Indonesian': 3,\n",
        "    'Italian': 2,\n",
        "    'Japanese': 2,\n",
        "    'Khmer': 3,\n",
        "    'Korean':2,\n",
        "    'Macedonian':3,\n",
        "    'Malagasy':3,\n",
        "    'Burmese':3,\n",
        "    'Dutch': 2\n",
        "}\n",
        "\n",
        "tier_res = {\n",
        "    1: [],\n",
        "    2: [],\n",
        "    3: []\n",
        "}\n",
        "\n",
        "for lan, tier in tiers_dict.items():\n",
        "  gpt_3_5_bleu_0s, gpt_3_5_bleu_2s, gpt_4o_bleu_0s, gpt_4o_bleu_2s = bleu_dict[lan]\n",
        "  tier_res[tier].append([gpt_3_5_bleu_0s, gpt_3_5_bleu_2s, gpt_4o_bleu_0s, gpt_4o_bleu_2s])\n",
        "\n",
        "print(\"\\t\\t\\t\\tBleu score\")\n",
        "print(\"\\t\\t gpt3.5 \\t\\t\\t gpt4o\")\n",
        "print(f\"tier \\t 0shot \\t\\t 2shot \\t\\t 0shot \\t\\t 2shot\\n\")\n",
        "for tier, bleu_s in tier_res.items():\n",
        "  bleu_s = np.array(bleu_s)\n",
        "  means = np.mean(bleu_s, axis=0)\n",
        "  stds = np.std(bleu_s, axis=0)\n",
        "  print(f\"{tier} \\t {means[0]:.2f}±{stds[0]:.2f} \\t {means[1]:.2f}±{stds[1]:.2f} \\t {means[2]:.2f}±{stds[2]:.2f} \\t {means[3]:.2f}±{stds[3]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of1fZsxyLJK0",
        "outputId": "0c840521-41f7-4ae7-f340-1c2acb5e766a"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\t\tBleu score\n",
            "\t\t gpt3.5 \t\t\t gpt4o\n",
            "tier \t 0shot \t\t 2shot \t\t 0shot \t\t 2shot\n",
            "\n",
            "1 \t 0.76±0.03 \t 0.77±0.00 \t 0.78±0.01 \t 0.78±0.01\n",
            "2 \t 0.53±0.21 \t 0.56±0.18 \t 0.56±0.20 \t 0.57±0.21\n",
            "3 \t 0.63±0.20 \t 0.64±0.20 \t 0.67±0.14 \t 0.68±0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NER"
      ],
      "metadata": {
        "id": "IWS7AUnaNaZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 105zhcFuStxs2BeQYfUqIXYa69ULITQ7F\n",
        "!gdown 1VQx4OE8xtmC_kZoRbHlLkB_-fD6Xax7M\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_pickle(\"barziokas.pkl.csv\")\n",
        "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G18v2bVfNccM",
        "outputId": "8da70eae-0a92-419c-fa42-a0782fe8017b"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=105zhcFuStxs2BeQYfUqIXYa69ULITQ7F\n",
            "To: /content/barziokas.csv\n",
            "100% 12.2M/12.2M [00:00<00:00, 104MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VQx4OE8xtmC_kZoRbHlLkB_-fD6Xax7M\n",
            "To: /content/barziokas.pkl.csv\n",
            "100% 7.85M/7.85M [00:00<00:00, 53.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predictions\n",
        "\n",
        "sample_test_df = test_df.sample(50, random_state=42)\n",
        "\n",
        "train_samples = train_df.sample(10, random_state=42)\n",
        "train_sample_1 = train_samples.iloc[2]\n",
        "train_sample_2 = train_samples.iloc[-2]\n",
        "x, y_true = sample_test_df.sentence, sample_test_df.tagset4\n",
        "\n",
        "\n",
        "system_content = '''\n",
        "Identify and label named entities in a given sentence using the specified NER tag set: `['S-LOC', 'O', 'B-ORG', 'E-ORG', 'B-PERSON', 'E-PERSON', 'I-ORG', 'B-LOC', 'E-LOC', 'S-PERSON', 'I-PERSON', 'S-ORG', 'S-MISC', 'B-MISC', 'I-MISC', 'E-MISC', 'I-LOC']`.\n",
        "You will be provided with a list of words, which form a sentence. Your task is to analyze this sentence and assign the appropriate named entity tag to each word.\n",
        "- For single-token entities, use the `S-` prefix followed by the appropriate entity type (e.g., `S-LOC` for a single-token location).\n",
        "- For multi-token entities, use the `B-`, `I-`, and `E-` prefixes to denote the beginning, inside, and end of the entity, respectively (e.g., `B-PERSON`, `I-PERSON`, `E-PERSON` for a person entity spanning multiple tokens).\n",
        "- Use the `O` tag for words that are not part of any named entity.\n",
        "Generate just a list with just the elements being the named entity tags corresponding to each word in the input list. Ensure that the tags correctly represent the boundaries and types of named entities as per the tag set provided.\n",
        "\n",
        "Tag Set:\n",
        "    - `S-LOC`: Single-token location entity.\n",
        "    - `O`: Outside any named entity.\n",
        "    - `B-ORG`: Beginning of an organization entity.\n",
        "    - `E-ORG`: End of an organization entity.\n",
        "    - `B-PERSON`: Beginning of a person entity.\n",
        "    - `E-PERSON`: End of a person entity.\n",
        "    - `I-ORG`: Inside an organization entity.\n",
        "    - `B-LOC`: Beginning of a location entity.\n",
        "    - `E-LOC`: End of a location entity.\n",
        "    - `S-PERSON`: Single-token person entity.\n",
        "    - `I-PERSON`: Inside a person entity.\n",
        "    - `S-ORG`: Single-token organization entity.\n",
        "    - `S-MISC`: Single-token miscellaneous entity.\n",
        "    - `B-MISC`: Beginning of a miscellaneous entity.\n",
        "    - `I-MISC`: Inside a miscellaneous entity.\n",
        "    - `E-MISC`: End of a miscellaneous entity.\n",
        "    - `I-LOC`: Inside a location entity.\n",
        "'''\n",
        "two_shots_list = [\n",
        "    ('user', \", \".join(train_sample_1.sentence)),\n",
        "    ('assistant', \", \".join(train_sample_1.tagset4)),\n",
        "    ('user', \", \".join(train_sample_2.sentence)),\n",
        "    ('assistant', \", \".join(train_sample_2.tagset4))\n",
        "]\n",
        "prompt_dict = get_prompts(system_content, two_shots_list)\n",
        "\n",
        "df_gpt_3_5 = get_gpt_response(prompt_dict, \"gpt-3.5-turbo\", x, y_true)\n",
        "df_gpt_4o = get_gpt_response(prompt_dict, \"gpt-4o\", x, y_true)"
      ],
      "metadata": {
        "id": "CYZOOk8fTYKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Results\n",
        "print(\"gpt-3.5 zero-shot\")\n",
        "report = classification_report(df_gpt_3_5.y_true.explode(), df_gpt_3_5.y_pred_zero_shot.explode(), labels=[\n",
        "    'S-LOC', 'B-LOC', 'I-LOC', 'E-LOC', 'S-ORG', 'B-ORG', 'I-ORG', 'E-ORG',\n",
        "    'S-PERSON', 'B-PERSON', 'I-PERSON', 'E-PERSON', 'S-MISC', 'B-MISC', 'I-MISC', 'E-MISC', 'O'\n",
        "], zero_division=0)\n",
        "print(report)\n",
        "\n",
        "print(\"\\ngpt-3.5 two-shot\")\n",
        "report = classification_report(df_gpt_3_5.y_true.explode(), df_gpt_3_5.y_pred_two_shot.explode(), labels=[\n",
        "    'S-LOC', 'B-LOC', 'I-LOC', 'E-LOC', 'S-ORG', 'B-ORG', 'I-ORG', 'E-ORG',\n",
        "    'S-PERSON', 'B-PERSON', 'I-PERSON', 'E-PERSON', 'S-MISC', 'B-MISC', 'I-MISC', 'E-MISC', 'O'\n",
        "], zero_division=0)\n",
        "print(report)\n",
        "\n",
        "print(\"\\ngpt-4o zero-shot\")\n",
        "report = classification_report(df_gpt_3_5.y_true.explode(), df_gpt_4o.y_pred_zero_shot.explode(), labels=[\n",
        "    'S-LOC', 'B-LOC', 'I-LOC', 'E-LOC', 'S-ORG', 'B-ORG', 'I-ORG', 'E-ORG',\n",
        "    'S-PERSON', 'B-PERSON', 'I-PERSON', 'E-PERSON', 'S-MISC', 'B-MISC', 'I-MISC', 'E-MISC', 'O'\n",
        "], zero_division=0)\n",
        "print(report)\n",
        "\n",
        "print(\"\\ngpt-4o two-shot\")\n",
        "report = classification_report(df_gpt_3_5.y_true.explode(), df_gpt_4o.y_pred_two_shot.explode(), labels=[\n",
        "    'S-LOC', 'B-LOC', 'I-LOC', 'E-LOC', 'S-ORG', 'B-ORG', 'I-ORG', 'E-ORG',\n",
        "    'S-PERSON', 'B-PERSON', 'I-PERSON', 'E-PERSON', 'S-MISC', 'B-MISC', 'I-MISC', 'E-MISC', 'O'\n",
        "], zero_division=0)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt-z-78f7BGW",
        "outputId": "5db5f322-0541-413e-b78f-e997f75a3340"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-3.5 zero-shot\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       S-LOC       0.16      0.29      0.21        14\n",
            "       B-LOC       0.00      0.00      0.00         2\n",
            "       I-LOC       0.00      0.00      0.00         1\n",
            "       E-LOC       0.00      0.00      0.00         2\n",
            "       S-ORG       0.25      0.18      0.21        22\n",
            "       B-ORG       0.33      0.33      0.33        12\n",
            "       I-ORG       0.60      0.38      0.46         8\n",
            "       E-ORG       0.33      0.33      0.33        12\n",
            "    S-PERSON       0.13      0.20      0.16        10\n",
            "    B-PERSON       0.08      0.10      0.09        10\n",
            "    I-PERSON       0.00      0.00      0.00         0\n",
            "    E-PERSON       0.09      0.10      0.10        10\n",
            "      S-MISC       0.00      0.00      0.00         9\n",
            "      B-MISC       0.00      0.00      0.00         1\n",
            "      I-MISC       0.00      0.00      0.00         2\n",
            "      E-MISC       0.00      0.00      0.00         1\n",
            "           O       0.93      0.90      0.91       990\n",
            "\n",
            "   micro avg       0.84      0.83      0.83      1106\n",
            "   macro avg       0.17      0.17      0.16      1106\n",
            "weighted avg       0.85      0.83      0.84      1106\n",
            "\n",
            "\n",
            "gpt-3.5 two-shot\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       S-LOC       0.14      0.14      0.14        14\n",
            "       B-LOC       0.00      0.00      0.00         2\n",
            "       I-LOC       0.00      0.00      0.00         1\n",
            "       E-LOC       0.00      0.00      0.00         2\n",
            "       S-ORG       0.33      0.05      0.08        22\n",
            "       B-ORG       0.23      0.25      0.24        12\n",
            "       I-ORG       0.50      0.50      0.50         8\n",
            "       E-ORG       0.36      0.33      0.35        12\n",
            "    S-PERSON       0.00      0.00      0.00        10\n",
            "    B-PERSON       0.12      0.20      0.15        10\n",
            "    I-PERSON       0.00      0.00      0.00         0\n",
            "    E-PERSON       0.14      0.20      0.17        10\n",
            "      S-MISC       0.20      0.11      0.14         9\n",
            "      B-MISC       0.00      0.00      0.00         1\n",
            "      I-MISC       0.00      0.00      0.00         2\n",
            "      E-MISC       0.00      0.00      0.00         1\n",
            "           O       0.93      0.93      0.93       990\n",
            "\n",
            "   micro avg       0.85      0.85      0.85      1106\n",
            "   macro avg       0.17      0.16      0.16      1106\n",
            "weighted avg       0.86      0.85      0.85      1106\n",
            "\n",
            "\n",
            "gpt-4o zero-shot\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       S-LOC       0.45      0.64      0.53        14\n",
            "       B-LOC       0.33      0.50      0.40         2\n",
            "       I-LOC       0.00      0.00      0.00         1\n",
            "       E-LOC       0.00      0.00      0.00         2\n",
            "       S-ORG       0.50      0.27      0.35        22\n",
            "       B-ORG       0.29      0.33      0.31        12\n",
            "       I-ORG       0.40      0.25      0.31         8\n",
            "       E-ORG       0.31      0.33      0.32        12\n",
            "    S-PERSON       0.56      0.50      0.53        10\n",
            "    B-PERSON       0.08      0.10      0.09        10\n",
            "    I-PERSON       0.00      0.00      0.00         0\n",
            "    E-PERSON       0.11      0.10      0.11        10\n",
            "      S-MISC       0.38      0.56      0.45         9\n",
            "      B-MISC       0.00      0.00      0.00         1\n",
            "      I-MISC       0.00      0.00      0.00         2\n",
            "      E-MISC       0.00      0.00      0.00         1\n",
            "           O       0.96      0.94      0.95       990\n",
            "\n",
            "    accuracy                           0.88      1106\n",
            "   macro avg       0.26      0.27      0.26      1106\n",
            "weighted avg       0.89      0.88      0.88      1106\n",
            "\n",
            "\n",
            "gpt-4o two-shot\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       S-LOC       0.50      0.43      0.46        14\n",
            "       B-LOC       0.00      0.00      0.00         2\n",
            "       I-LOC       0.00      0.00      0.00         1\n",
            "       E-LOC       0.00      0.00      0.00         2\n",
            "       S-ORG       0.62      0.45      0.53        22\n",
            "       B-ORG       0.27      0.33      0.30        12\n",
            "       I-ORG       0.33      0.38      0.35         8\n",
            "       E-ORG       0.23      0.25      0.24        12\n",
            "    S-PERSON       0.29      0.20      0.24        10\n",
            "    B-PERSON       0.17      0.20      0.18        10\n",
            "    I-PERSON       0.00      0.00      0.00         0\n",
            "    E-PERSON       0.17      0.10      0.12        10\n",
            "      S-MISC       0.20      0.44      0.28         9\n",
            "      B-MISC       0.00      0.00      0.00         1\n",
            "      I-MISC       0.00      0.00      0.00         2\n",
            "      E-MISC       0.00      0.00      0.00         1\n",
            "           O       0.95      0.93      0.94       990\n",
            "\n",
            "    accuracy                           0.87      1106\n",
            "   macro avg       0.22      0.22      0.21      1106\n",
            "weighted avg       0.88      0.87      0.87      1106\n",
            "\n"
          ]
        }
      ]
    }
  ]
}