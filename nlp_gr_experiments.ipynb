{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vxEDv7gtXkGA",
        "BZhvXSwwmqGZ",
        "lyOODeeV-BJD",
        "VNgrd1Ht-LFw",
        "O97r-Vgw8gEA",
        "5yviycFr8VUy",
        "lrkgnmmkQbZj",
        "fTRky8I4p28I",
        "4zo3SeXAKLPl",
        "AuxJQeGtqV74",
        "5Kvx725Iqkju",
        "gBMh5tneqmq6",
        "yim6eMcMzLt7",
        "Aoaoei2VzHia"
      ],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greek-nlp/benchmark/blob/main/nlp_gr_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialisation\n"
      ],
      "metadata": {
        "id": "k2MjPuTks5tC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data and config"
      ],
      "metadata": {
        "id": "vxEDv7gtXkGA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8ugi-oDHOvf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install boto3\n",
        "import boto3\n",
        "from botocore.config import Config\n",
        "from botocore.exceptions import ClientError"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from google.colab import files\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import importlib\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gNyd-aJOmzeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Upload the `aws.json` file: ')\n",
        "files.upload()\n",
        "credentials = json.load(open('aws.json'))"
      ],
      "metadata": {
        "id": "pN3__JvjDCFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up the model"
      ],
      "metadata": {
        "id": "BZhvXSwwmqGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the boto3 client for Bedrock\n",
        "bedrock_client = boto3.client(\n",
        "    'bedrock',\n",
        "    aws_access_key_id=credentials['aws_access_key_id'],\n",
        "    aws_secret_access_key=credentials['aws_secret_access_key'],\n",
        "    region_name=credentials['aws_region']\n",
        ")\n",
        "bedrock_client.list_foundation_models()['modelSummaries']"
      ],
      "metadata": {
        "id": "muC3NulMHSL9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the native inference API to send a text message to Meta Llama 3.\n",
        "# Create a Bedrock Runtime client in the AWS Region of your choice.\n",
        "client = boto3.client(\"bedrock-runtime\",\n",
        "                      aws_access_key_id=credentials['aws_access_key_id'],\n",
        "                      aws_secret_access_key=credentials['aws_secret_access_key'],\n",
        "                      region_name=credentials['aws_region'])\n",
        "\n",
        "model_id = \"meta.llama3-70b-instruct-v1:0\""
      ],
      "metadata": {
        "id": "wTiUHPnIbO4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def llama_prompt(text,\n",
        "                 instruction=\"Correct any grammatical errors in the following text but do not change the text otherwise, and return just the corrected text.\",\n",
        "                 shots=\"\",\n",
        "                 max_len=512,\n",
        "                 model_id=model_id,\n",
        "                 client=client):\n",
        "  # Embed the prompt in Llama 3's instruction format.\n",
        "  formatted_prompt = f\"\"\"\n",
        "  <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "  {instruction}\n",
        "  {shots}\n",
        "  user: {text}\n",
        "  <|eot_id|>\n",
        "  <|start_header_id|>assistant<|end_header_id|>\n",
        "  \"\"\"\n",
        "\n",
        "  # Format the request payload using the model's native structure.\n",
        "  native_request = {\n",
        "      \"prompt\": formatted_prompt,\n",
        "      \"max_gen_len\": max_len,\n",
        "      \"temperature\": 0.5,\n",
        "  }\n",
        "\n",
        "  # Convert the native request to JSON.\n",
        "  request = json.dumps(native_request)\n",
        "\n",
        "  try:\n",
        "      # Invoke the model with the request.\n",
        "      response = client.invoke_model(modelId=model_id, body=request)\n",
        "\n",
        "  except (ClientError, Exception) as e:\n",
        "      print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
        "      exit(1)\n",
        "\n",
        "  # Decode the response body.\n",
        "  model_response = json.loads(response[\"body\"].read())\n",
        "\n",
        "  # Extract and print the response text.\n",
        "  response_text = model_response[\"generation\"]\n",
        "  return response_text"
      ],
      "metadata": {
        "id": "BsjokpwRB_97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Access the benchmark"
      ],
      "metadata": {
        "id": "lyOODeeV-BJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/greek-nlp/gen-a.git\n",
        "!pip install zenodo-get\n",
        "!pip install datasets\n",
        "!pip install conll-df\n",
        "\n",
        "import pandas as pd\n",
        "import importlib\n",
        "\n",
        "gr_data = pd.read_csv('gen-a/data.csv')\n",
        "gena = importlib.import_module(\"gen-a.data_wrapper\")"
      ],
      "metadata": {
        "id": "800OqLKSaqRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GEC"
      ],
      "metadata": {
        "id": "VNgrd1Ht-LFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "korre = gena.KorreDt(datasets=gr_data)\n",
        "train = korre.get('train')"
      ],
      "metadata": {
        "id": "T1lzV8pW-KbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = train.original_text.values\n",
        "train['llama'] = [llama_prompt(t) for t in tqdm(texts)]"
      ],
      "metadata": {
        "id": "aU3aDbD4u-sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pywer\n",
        "import pywer\n",
        "\n",
        "wer = pywer.wer(train.original_text.values, train.llama.str.strip().values)\n",
        "cer = pywer.cer(train.original_text.values, train.llama.str.strip().values)\n",
        "print(f\"WER: {wer:.2f}, CER: {cer:.2f}\")"
      ],
      "metadata": {
        "id": "54Wwet0vvwQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.sample().values[0]\n",
        "train.to_csv('korre_llama3-70b-i_0s.csv')"
      ],
      "metadata": {
        "id": "XsKBugWozWuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shots = \"\"\" Here are a couple of examples:\n",
        "1.\n",
        "user: Δεν ήθελε να θεωρηθεί προκατειλημένος και για αυτό δε συνέχισε τη συνεργασία περεταίρω.\n",
        "assistant: Δεν ήθελε να θεωρηθεί προκατειλημμένος και για αυτό δε συνέχισε τη συνεργασία περαιτέρω.\n",
        "2.\n",
        "user: Το περιθώριο των κερδών τους δεν αλλάζουν εύκολα.\n",
        "assistant: Το περιθώριο των κερδών τους δεν αλλάζει εύκολα.\n",
        "\"\"\"\n",
        "train['llama2s'] = [llama_prompt(t, shots) for t in tqdm(texts)]"
      ],
      "metadata": {
        "id": "LCdxgNUWOGqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wer = pywer.wer(train.original_text.values, train.llama2s.str.strip().values)\n",
        "cer = pywer.cer(train.original_text.values, train.llama2s.str.strip().values)\n",
        "print(f\"WER: {wer:.2f}, CER: {cer:.2f}\")"
      ],
      "metadata": {
        "id": "Jc7PxE_oACzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('korre_llama3-70b-i.csv')"
      ],
      "metadata": {
        "id": "HRTVRhsYBXHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[train.original_text == train.corrected_text].shape"
      ],
      "metadata": {
        "id": "wumP6RUnDfio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Toxicity"
      ],
      "metadata": {
        "id": "O97r-Vgw8gEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zampieri = gena.ZampieriDt(datasets = gr_data)\n",
        "zampieri_test = zampieri.get('test')"
      ],
      "metadata": {
        "id": "7ABweeEpDlIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruct = \"You are a Greek moderator and you are given a text, return 1 if the text is offensive and 0 if not. Only the values 1 or 0 should be returned.\"\n",
        "zampieri_test['llama'] = [llama_prompt(text=t, instruction=instruct, max_len=10) for t in tqdm(zampieri_test.text.values)]"
      ],
      "metadata": {
        "id": "MZpVG2Gy8hci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zampieri_test.llama.value_counts()[:5]"
      ],
      "metadata": {
        "id": "Pcu7m-bDbLR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(zampieri_test.subtask_a, zampieri_test.llama.apply(lambda x: 1 if '1' in x else 0).values))"
      ],
      "metadata": {
        "id": "Gt5rfgLs-E2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zampieri_test.to_csv('toxicity.csv')"
      ],
      "metadata": {
        "id": "ZcLkiSfQjy_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shots = \"\"\" Here are a couple of labelled examples:\n",
        "user: Πρέπει να πεθάνεις.\n",
        "assistant: 1\n",
        "user: Αυτή είναι μία ωραία εκπομπή.\n",
        "assistant: 0\n",
        "\"\"\"\n",
        "zampieri_test['llama2s'] = [llama_prompt(text=t, instruction=instruct, shots=shots, max_len=10) for t in tqdm(zampieri_test.text.values)]"
      ],
      "metadata": {
        "id": "5hiZPyKg9lQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(zampieri_test.subtask_a, zampieri_test.llama2s.apply(lambda x: 1 if x.strip()=='1' else 0).values))"
      ],
      "metadata": {
        "id": "WPM-iQirbnh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MT"
      ],
      "metadata": {
        "id": "5yviycFr8VUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prokopidis_mt = gena.ProkopidisMtDt(datasets=gr_data)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "for lang in prokopidis_mt.target_langs:\n",
        "  print(f\"Language: {lang} ({prokopidis_mt.langs_dict[lang]})\")\n",
        "  display(prokopidis_mt.get(lang, 'train').sample())"
      ],
      "metadata": {
        "id": "vutj82AMmA-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng = prokopidis_mt.get('eng', 'test').copy()\n",
        "jpn = prokopidis_mt.get('jpn', 'test').copy()\n",
        "fas = prokopidis_mt.get('fas', 'test').copy()\n",
        "\n",
        "#eng = pd.read_csv('eng_llama3_70b_i.csv')\n",
        "#jpn = pd.read_csv('jpn_llama3_70b_i.csv')\n",
        "#fas = pd.read_csv('fas_llama3_70b_i.csv')\n",
        "#from ast import literal_eval\n",
        "#eng.target = eng.target.apply(literal_eval)\n",
        "#jpn.target = jpn.target.apply(literal_eval)\n",
        "#fas.target = fas.target.apply(literal_eval)\n",
        "#eng.llama.fillna('', inplace=True)\n",
        "#jpn.llama.fillna('', inplace=True)\n",
        "#fas.llama.fillna('', inplace=True)"
      ],
      "metadata": {
        "id": "c3TMzC3jBOR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruct = lambda source='ell', target='eng': f\"Given a text in {source}, translate it to {target}. Only the translation should be returned.\"\n",
        "eng['llama'] = [llama_prompt(text=t, instruction=instruct()) for t in tqdm(eng.source.values)]\n",
        "jpn['llama'] = [llama_prompt(text=t, instruction=instruct(target='jpn')) for t in tqdm(jpn.source.values)]\n",
        "fas['llama'] = [llama_prompt(text=t, instruction=instruct(target='fas')) for t in tqdm(fas.source.values)]\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1jbgDQj9bYQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng.to_csv('eng_llama3_70b_i.csv')\n",
        "jpn.to_csv('jpn_llama3_70b_i.csv')\n",
        "fas.to_csv('fas_llama3_70b_i.csv')"
      ],
      "metadata": {
        "id": "KOPtDHTCKQGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pywer\n",
        "import pywer\n",
        "\n",
        "def ter(hyp, refs, unit='word'):\n",
        "  \"\"\"\n",
        "  Compute the translation error rate between a hypothesis and a reference.\n",
        "  If a list of references is provided, the minimum score is returned.\n",
        "  :param hyp: The hypothesis.\n",
        "  :param refs: The reference or list of references.\n",
        "  :return: The TER score.\n",
        "  \"\"\"\n",
        "  if isinstance(refs, str):\n",
        "    refs = [refs]\n",
        "  scores = [pywer.wer(refs, [hyp]) if unit=='word' else pywer.cer(refs, [hyp]) for ref in refs]\n",
        "  return min(scores)\n",
        "\n",
        "# Compute TER (word)\n",
        "score = eng.apply(lambda row: ter(row.llama, row.target), axis=1)\n",
        "print(f\"Eng: {score.mean():.2f} ({score.std():.2f})\")\n",
        "\n",
        "score = jpn.apply(lambda row: ter(row.llama, row.target), axis=1)\n",
        "print(f\"Jpn: {score.mean():.2f} ({score.std():.2f})\")\n",
        "\n",
        "score = fas.apply(lambda row: ter(row.llama, row.target), axis=1)\n",
        "print(f\"Fas: {score.mean():.2f} ({score.std():.2f})\")"
      ],
      "metadata": {
        "id": "GQBdK_3HGrmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute TER (char)\n",
        "score = eng.apply(lambda row: ter(row.llama, row.target, 'char'), axis=1)\n",
        "print(f\"Eng: {score.mean():.2f} ({score.std():.2f})\")\n",
        "\n",
        "score = jpn.apply(lambda row: ter(row.llama, row.target, 'char'), axis=1)\n",
        "print(f\"Jpn: {score.mean():.2f} ({score.std():.2f})\")\n",
        "\n",
        "score = fas.apply(lambda row: ter(row.llama, row.target, 'char'), axis=1)\n",
        "print(f\"Fas: {score.mean():.2f} ({score.std():.2f})\")"
      ],
      "metadata": {
        "id": "h0mLW3CPMThD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTscore\n",
        "#!pip install evaluate bert_score\n",
        "from evaluate import load\n",
        "bertscore = load(\"bertscore\")\n",
        "results_en = [bertscore.compute(predictions=[p], references=[t[0]], lang=\"en\") for p,t in tqdm(zip(eng.llama.values, eng.target.values))]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JEjcTMhHOoF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng['bertscore_f1'] = [r['f1'][0] for r in results_en]\n",
        "eng['bertscore_precision'] = [r['precision'][0] for r in results_en]\n",
        "eng['bertscore_recall'] = [r['recall'][0] for r in results_en]\n",
        "eng.bertscore_f1.mean()"
      ],
      "metadata": {
        "id": "8rKdt3LslJzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_ja = [bertscore.compute(predictions=[p], references=[t[0]], lang=\"ja\") for p, t in tqdm(zip(jpn.llama.values, jpn.target.values))]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7iSlQ5nrXb43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpn['bertscore_f1'] = [r['f1'][0] for r in results_ja]\n",
        "jpn['bertscore_precision'] = [r['precision'][0] for r in results_ja]\n",
        "jpn['bertscore_recall'] = [r['recall'][0] for r in results_ja]\n",
        "jpn.bertscore_f1.mean()"
      ],
      "metadata": {
        "id": "0TxP3uz5lWsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_fa = [bertscore.compute(predictions=[p], references=[t[0]], lang=\"fa\") for p, t in tqdm(zip(fas.llama.values, fas.target.values))]"
      ],
      "metadata": {
        "id": "zvzdThZcbEdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fas['bertscore_f1'] = [r['f1'][0] for r in results_fa]\n",
        "fas['bertscore_precision'] = [r['precision'][0] for r in results_fa]\n",
        "fas['bertscore_recall'] = [r['recall'][0] for r in results_fa]\n",
        "fas.bertscore_f1.mean()"
      ],
      "metadata": {
        "id": "sK--pFqLlbua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng.to_csv('eng_llama3_70b_i_bertscore.csv')\n",
        "jpn.to_csv('jpn_llama3_70b_i_bertscore.csv')\n",
        "fas.to_csv('fas_llama3_70b_i_bertscore.csv')"
      ],
      "metadata": {
        "id": "oVJ0drH5liqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intent"
      ],
      "metadata": {
        "id": "lrkgnmmkQbZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rizou = gena.RizouDt(datasets=gr_data).get('test')\n",
        "rizou.sample()"
      ],
      "metadata": {
        "id": "_zs4CZcSQECt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = list(rizou.intent.unique())\n",
        "rizou.intent.value_counts().plot.barh(figsize=(8,2));"
      ],
      "metadata": {
        "id": "GY5EESkhQwDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rizou.text.apply(len).describe()"
      ],
      "metadata": {
        "id": "8c801HcXUe2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruct = \"Given a text, provide the intent of the text. Only the intent should be returned. Here is the list of possible intents: \" + ', '.join(classes)\n",
        "rizou['llama'] = [llama_prompt(text=t, instruction=instruct) for t in tqdm(rizou.text.values)]"
      ],
      "metadata": {
        "id": "q-nd2FEGQ4rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rizou.to_csv('rizou.csv')"
      ],
      "metadata": {
        "id": "16eH3PczRd3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fixing the values\n",
        "rizou['llama_fixed'] = rizou.llama.apply(lambda x: x.strip() if str(x).strip() in classes else random.choice(classes))\n",
        "rizou[rizou.llama.apply(lambda x: str(x).strip() not in classes)].shape"
      ],
      "metadata": {
        "id": "OkjhtyHBnRRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(rizou.intent, rizou.llama_fixed))"
      ],
      "metadata": {
        "id": "ub_Rf1TwpFra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarisation"
      ],
      "metadata": {
        "id": "fTRky8I4p28I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "koniaris = gena.KoniarisDt(datasets = gr_data)"
      ],
      "metadata": {
        "id": "BPajrrnRpuOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ = koniaris.get('test')\n",
        "summ.sample()"
      ],
      "metadata": {
        "id": "pzsLxHXn_CdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ.text.apply(len).describe()"
      ],
      "metadata": {
        "id": "MnTEXkPsWPId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ.text.str.split().apply(len).describe()"
      ],
      "metadata": {
        "id": "lECNg1cTXJwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ.text.str.split().apply(len).hist(bins=100, figsize=(8,2));"
      ],
      "metadata": {
        "id": "GGeIHRHZBiMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_short = summ[summ.text.str.split().apply(len)<1000]\n",
        "summ_short.text.str.split().apply(len).hist(bins=100, figsize=(8,2));"
      ],
      "metadata": {
        "id": "ukuh8onj_xyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_short.text.apply(len).describe()"
      ],
      "metadata": {
        "id": "dCPM3x5dW7iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruct = \"Given a Greek legal text, provide its summary also in Greek. Only the summary should be returned.\"\n",
        "summ_short['llama'] = [llama_prompt(text=t, instruction=instruct) for t in tqdm(summ_short.text.values)]"
      ],
      "metadata": {
        "id": "VdbODuPx_PC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_short.sample()"
      ],
      "metadata": {
        "id": "OUOwpU5CQVMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install evaluate bert_score\n",
        "from evaluate import load\n",
        "bertscore = load(\"bertscore\")\n",
        "bert_scores = [bertscore.compute(predictions=[p], references=[t[0]], lang=\"gr\") for p,t in tqdm(zip(summ_short.llama.values, summ_short.summary.values))]"
      ],
      "metadata": {
        "id": "Uh0-UVj3TQms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_short['bert_f1'] = [r['f1'][0] for r in bert_scores]\n",
        "summ_short['bert_precision'] = [r['precision'][0] for r in bert_scores]\n",
        "summ_short['bert_recall'] = [r['recall'][0] for r in bert_scores]\n",
        "summ_short.bert_f1.mean()"
      ],
      "metadata": {
        "id": "SL5qOfo7Vyzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "rouge_scores = [rouge.get_scores(p, t) for p,t in tqdm(zip(summ_short.llama.values, summ_short.summary.values))]"
      ],
      "metadata": {
        "id": "D3TsHzg-UwDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_scores[0][0]"
      ],
      "metadata": {
        "id": "T_RROqZSWqye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_short['rouge1_f1'] = [r[0]['rouge-1']['f'] for r in rouge_scores]\n",
        "summ_short['rouge1_precision'] = [r[0]['rouge-1']['p'] for r in rouge_scores]\n",
        "summ_short['rouge1_recall'] = [r[0]['rouge-1']['r'] for r in rouge_scores]"
      ],
      "metadata": {
        "id": "vPbZa1D3V9u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_short['rouge2_f1'] = [r[0]['rouge-2']['f'] for r in rouge_scores]\n",
        "summ_short['rouge2_precision'] = [r[0]['rouge-2']['p'] for r in rouge_scores]\n",
        "summ_short['rouge2_recall'] = [r[0]['rouge-2']['r'] for r in rouge_scores]"
      ],
      "metadata": {
        "id": "1j6v5ov-XR6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_short['rougel_f1'] = [r[0]['rouge-l']['f'] for r in rouge_scores]\n",
        "summ_short['rougel_precision'] = [r[0]['rouge-l']['p'] for r in rouge_scores]\n",
        "summ_short['rougel_recall'] = [r[0]['rouge-l']['r'] for r in rouge_scores]"
      ],
      "metadata": {
        "id": "pMYpGHZsXVtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_short.to_csv('summ_koniaris.csv')\n",
        "summ_short[summ_short.columns[6:]].agg(['mean', 'std', 'sem'])"
      ],
      "metadata": {
        "id": "qjec4OQWXarx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language modeling"
      ],
      "metadata": {
        "id": "4zo3SeXAKLPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/ipavlopoulos/lm.git\n",
        "from lm.markov.models import LM"
      ],
      "metadata": {
        "id": "22Go-EfnKTZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets = {'dritsa21':gena.DritsaDt(datasets=gr_data).get('train'),\n",
        "                'barzokas20':gena.BarzokasDt(datasets=gr_data).get('train'),\n",
        "                'prokopidis20':gena.ProkopidisCrawledDt(datasets=gr_data).get('train'),\n",
        "                'papantoniou23': gena.PapantoniouDt(datasets=gr_data).get('train')}\n",
        "\n",
        "train_sets = {}\n",
        "test_sets = {}\n",
        "for dataset_name in raw_datasets:\n",
        "  print(dataset_name)\n",
        "  dataset = raw_datasets[dataset_name]\n",
        "  dataset = dataset[dataset.text.notna()]\n",
        "  dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "  train_sets[dataset_name] = dataset.text.apply(lambda x: x[:100]).iloc[:1000] # lower lim\n",
        "  test_sets[dataset_name] = dataset.text.apply(lambda x: x[:100]).iloc[1000:1500]"
      ],
      "metadata": {
        "id": "BFj0s_KnKY7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppls, ppls_std = {}, {}\n",
        "for dname in raw_datasets:\n",
        "  train = train_sets[dname]\n",
        "  test = test_sets[dname]\n",
        "  lm = LM(gram=\"CHAR\")\n",
        "  lm.train(' '.join(train.values)[:65000]) # length of min dataset\n",
        "  ppls[dname], ppls_std[dname] = {}, {}\n",
        "  for dname2 in raw_datasets:\n",
        "    scores = test_sets[dname2].apply(lm.cross_entropy)\n",
        "    ppls[dname][dname2] = scores.mean()\n",
        "    ppls_std[dname][dname2] = scores.std()"
      ],
      "metadata": {
        "id": "wijpuFpcNMUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "ppls_pd = pd.DataFrame(ppls)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(ppls_pd, annot=True, cmap='coolwarm', linewidths=0.5,\n",
        "            linecolor='black', cbar_kws={'label': 'PPL'});\n",
        "\n",
        "# Add labels and a title\n",
        "plt.title('PPL per LM per dataset'); plt.xlabel('Dataset'); plt.ylabel('LM');\n",
        "plt.tight_layout();\n",
        "plt.savefig('ppl_heatmap.pdf', dpi=300, format='PDF')"
      ],
      "metadata": {
        "id": "1qETQ5w1NXj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering"
      ],
      "metadata": {
        "id": "ukaBIDhLqUsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clustering Accuracy\n",
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment as hungarian\n",
        "\n",
        "def hungarian_acc(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    y_true = y_true.astype(np.int64)\n",
        "    assert y_pred.size == y_true.size\n",
        "    D = max(y_pred.max(), y_true.max()) + 1\n",
        "    w = np.zeros((D, D), dtype=np.int64)\n",
        "    for i in range(y_pred.size):\n",
        "        w[y_pred[i], y_true[i]] += 1\n",
        "\n",
        "    row_ind, col_ind = hungarian(w.max() - w)\n",
        "    return sum([w[i, j] for i, j in zip(row_ind, col_ind)]) * 1.0 / y_pred.size"
      ],
      "metadata": {
        "id": "YcaEyVZ0LO0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "papaloukas = gena.PapaloukasDt(datasets=gr_data).get('test')"
      ],
      "metadata": {
        "id": "hKG4pr1-qVeP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papaloukas.sample()"
      ],
      "metadata": {
        "id": "U-0B1RtUMbHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.violinplot(papaloukas.text.apply(lambda x: min(len(x), 6000)));\n",
        "sns.despine(left=True, bottom=True);"
      ],
      "metadata": {
        "id": "V-5v-iCEOHLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TFIDF"
      ],
      "metadata": {
        "id": "XCQR_AD2OAFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "# Convert the text documents to a matrix of TF-IDF features\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(papaloukas.text.values)\n",
        "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
        "\n",
        "# Print the shape of the TF-IDF matrix\n",
        "print(\"TF-IDF matrix shape:\", tfidf_matrix.shape)"
      ],
      "metadata": {
        "id": "HBVY0JBNNb41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
        "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
        "from sklearn.metrics import adjusted_rand_score as ari\n",
        "\n",
        "test = papaloukas\n",
        "# kmeans for k equal to number of labels (volumes, chapters, subjects)\n",
        "for num_clusters in (47, 374, 1685):\n",
        "  print(f\"K={num_clusters}\")\n",
        "  km = KMeans(n_clusters=num_clusters, random_state=42, n_init='auto')\n",
        "  km.fit(tfidf_matrix)\n",
        "  test[f'kmeans{num_clusters}'] = km.labels_\n",
        "  print(f\"NMI: {nmi(test.volume.values, km.labels_):.4f}\")\n",
        "  print(f\"AMI: {ami(test.volume.values, km.labels_):.4f}\")\n",
        "  print(f\"ACC: {hungarian_acc(test.volume.values, km.labels_):.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "YJwS2A4VNe_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = {47: 'volume', 374:'chapter', 1685:'subject'}\n",
        "for num_clusters in ground_truth:\n",
        "  print(f\"K={num_clusters}\")\n",
        "  print(f\"NMI: {nmi(test[ground_truth[num_clusters]].values, test[f'kmeans{num_clusters}']):.4f}\")\n",
        "  print(f\"AMI: {ami(test[ground_truth[num_clusters]], test[f'kmeans{num_clusters}']):.4f}\")\n",
        "  print(f\"ACC: {hungarian_acc(test[ground_truth[num_clusters]], test[f'kmeans{num_clusters}']):.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "Mz4ottWhNjxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructor\n",
        "* Texts have a length that is up to 6k characters\n",
        "* Instructor's tokeniser has a limit of 512 tokens\n",
        "* Texts are also in Greek (Instructor is not multilingual)"
      ],
      "metadata": {
        "id": "7Z2SQf31OCei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "model = SentenceTransformer('hkunlp/instructor-large') # Using a sentence-transformer model\n",
        "instruction = \"Instruction: Compute representations for text clustering\"\n",
        "papaloukas['instructor'] = [model.encode(f\"{instruction}: {t}\") for t in tqdm(papaloukas.text.values)]\n",
        "papaloukas.to_pickle('papaloukas-instructor.pkl')"
      ],
      "metadata": {
        "id": "QtM-VjbMsYhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload the saved dataframe including the Instructor embeddings\n",
        "papaloukas = pd.read_pickle('papaloukas-instructor.pkl')"
      ],
      "metadata": {
        "id": "FlD0lV8XOmVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Run KMeans on top of the Instructor embeddings\n",
        "* Limitation: Instructor is not multilingual by default"
      ],
      "metadata": {
        "id": "FCdm7Iq9Ss9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
        "from sklearn.metrics import silhouette_score as sil\n",
        "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
        "from sklearn.metrics import adjusted_rand_score as ari\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "\n",
        "test = papaloukas\n",
        "embeddings = normalize(np.array(papaloukas.instructor.tolist()))\n",
        "\n",
        "# kmeans for k equal to number of labels (volumes, chapters, subjects)\n",
        "for num_clusters in (47, 374, 1685):\n",
        "  print(f\"K={num_clusters}\")\n",
        "  km = KMeans(n_clusters=num_clusters, random_state=42, n_init='auto')\n",
        "  km.fit(embeddings)\n",
        "  test[f'kmeans{num_clusters}'] = km.labels_\n",
        "  print(f\"NMI: {nmi(test.volume.values, km.labels_):.4f}\")\n",
        "  print(f\"AMI: {ami(test.volume.values, km.labels_):.4f}\")\n",
        "  print(f\"ARI: {ari(test.volume.values, km.labels_):.4f}\")\n",
        "  print()\n",
        "\n",
        "ground_truth = {47: 'volume', 374:'chapter', 1685:'subject'}\n",
        "for num_clusters in ground_truth:\n",
        "  print(f\"K={num_clusters}\")\n",
        "  print(f\"NMI: {nmi(test[ground_truth[num_clusters]].values, test[f'kmeans{num_clusters}']):.4f}\")\n",
        "  print(f\"AMI: {ami(test[ground_truth[num_clusters]], test[f'kmeans{num_clusters}']):.4f}\")\n",
        "  print(f\"ARI: {ari(test[ground_truth[num_clusters]], test[f'kmeans{num_clusters}']):.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "ALglq61TNgKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarise+Translate+Embed (STE)"
      ],
      "metadata": {
        "id": "mih4VfpjTDJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = '''Given a legal text in Greek, summarise and translate it to English.\n",
        "Limit your response to 200 tokens; out directly the English translation; return no other text (e.g., do not start with \"Here is the English translation\").\n",
        "'''\n",
        "t = papaloukas.text.iloc[0]\n",
        "print(t, '\\n', llama_prompt(text=t[:6000], instruction=instruction, max_len=200))"
      ],
      "metadata": {
        "id": "b_5CjqrXTNlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_translate(text, max_out_len=200, max_in_len=2000):\n",
        "  instruction = f'Given a legal text in Greek, summarise and translate it to English. Limit your response to {max_out_len} tokens; out directly the English translation; return no other text (e.g., do not start with \"Here is the English translation\").'\n",
        "  try:\n",
        "    return llama_prompt(text=text[:max_in_len], instruction=instruction, max_len=max_out_len)\n",
        "  except:\n",
        "    print(f'\\nERROR\\nTEXT: {text}\\n')\n",
        "    return None\n",
        "\n",
        "papaloukas['llama_en_sum'] = [sum_translate(t) for t in tqdm(papaloukas.text.values)]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ef0n1V7jU3gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "f = 'papaloukas_sum_translate.csv'\n",
        "papaloukas.to_csv(f)\n",
        "files.download(f)"
      ],
      "metadata": {
        "id": "wHGygxhSxGOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papaloukas = pd.read_csv('papaloukas_sum_translate.csv', index_col=0)\n",
        "papaloukas.sample()"
      ],
      "metadata": {
        "id": "OpdevwjwxccO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* TFIDF of English summaries"
      ],
      "metadata": {
        "id": "9nqkv-HRj0x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
        "from sklearn.metrics import silhouette_score as sil\n",
        "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
        "from sklearn.metrics import adjusted_rand_score as ari\n",
        "\n",
        "# tackling empty values\n",
        "papaloukas['llama_en_sum'] = papaloukas['llama_en_sum'].fillna('')\n",
        "\n",
        "# Convert the text documents to a matrix of TF-IDF features\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(papaloukas.llama_en_sum.values)\n",
        "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
        "\n",
        "# Print the shape of the TF-IDF matrix\n",
        "print(\"TF-IDF matrix shape:\", tfidf_matrix.shape)\n",
        "\n",
        "test = papaloukas\n",
        "\n",
        "# kmeans for k equal to number of labels (volumes, chapters, subjects)\n",
        "for K, level in ((47,'volume'), (374,'chapter'), (1685,'subject')):\n",
        "  print(f\"K={K}\")\n",
        "  km = KMeans(n_clusters=K, random_state=42, n_init='auto')\n",
        "  km.fit(tfidf_matrix)\n",
        "  test[f'kmeans{K}'] = km.labels_\n",
        "  print(f\"NMI: {nmi(test[level].values, km.labels_):.4f}\")\n",
        "  print(f\"AMI: {ami(test[level].values, km.labels_):.4f}\")\n",
        "  print(f\"ACC: {hungarian_acc(test[ground_truth[K]], test[f'kmeans{K}']):.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "vh3VHFm2jP9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "model = SentenceTransformer('hkunlp/instructor-large') # Using a sentence-transformer model\n",
        "instruction = \"Compute an embedding for this English legal text for clustering: \"\n",
        "papaloukas['ste'] = [model.encode(f\"{instruction}: {t}\") for t in tqdm(papaloukas.llama_en_sum.values)]"
      ],
      "metadata": {
        "id": "SO8HBIlf3L3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papaloukas.to_pickle('papaloukas_sum_translate_embed.pkl', protocol=4)\n",
        "from google.colab import files\n",
        "files.download('papaloukas_sum_translate_embed.pkl')"
      ],
      "metadata": {
        "id": "1PpXeVd95Q56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papaloukas = pd.read_pickle('papaloukas_sum_translate_embed.pkl')"
      ],
      "metadata": {
        "id": "2-tXr-vkQwWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
        "from sklearn.metrics import silhouette_score as sil\n",
        "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
        "from sklearn.metrics import adjusted_rand_score as ari\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "test = papaloukas\n",
        "embeddings = np.vstack(test.ste.values)\n",
        "\n",
        "for K, level in ((47,'volume'), (374,'chapter'), (1685,'subject')):\n",
        "  print(f\"K={K}\")\n",
        "  km = KMeans(n_clusters=K, random_state=42, n_init='auto')\n",
        "  km.fit(embeddings)\n",
        "  test[f'kmeans{K}'] = km.labels_\n",
        "  print(f\"NMI: {nmi(test[level].values, km.labels_):.4f}\")\n",
        "  print(f\"AMI: {ami(test[level].values, km.labels_):.4f}\")\n",
        "  print(f\"ACC: {hungarian_acc(test[ground_truth[K]], test[f'kmeans{K}']):.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "zG0jTi1A5i4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structure prediction (POS, NER)"
      ],
      "metadata": {
        "id": "AuxJQeGtqV74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NER"
      ],
      "metadata": {
        "id": "5Kvx725Iqkju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barziokas = gena.BarziokasDt(datasets=gr_data).get('test')\n",
        "barziokas.sample()"
      ],
      "metadata": {
        "id": "ZbMInt02qYqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: generate a prompt for llama for NER, using the following labels: ['S-LOC', 'O', 'B-ORG', 'E-ORG', 'B-PERSON', 'E-PERSON', 'I-ORG', 'B-LOC', 'E-LOC', 'S-PERSON', 'I-PERSON', 'S-ORG', 'S-MISC', 'B-MISC', 'I-MISC', 'E-MISC', 'I-LOC']. A sequence of labels should be returned and no other text. Add a few examples.\n",
        "\n",
        "instruction = \"\"\"You are a Greek NLP expert and you are given a text. Return a sequence of NER labels for each token in the text. The labels should be chosen from the following list: ['S-LOC', 'O', 'B-ORG', 'E-ORG', 'B-PERSON', 'E-PERSON', 'I-ORG', 'B-LOC', 'E-LOC', 'S-PERSON', 'I-PERSON', 'S-ORG', 'S-MISC', 'B-MISC', 'I-MISC', 'E-MISC', 'I-LOC']. Do not return any other text.\n",
        "Here are a couple of labelled examples:\n",
        "\n",
        "user: Η Αθήνα είναι η πρωτεύουσα της Ελλάδας.\n",
        "assistant: B-LOC E-LOC O O O B-LOC E-LOC O\n",
        "\n",
        "user: Ο Αλέξης Τσίπρας είναι πρωθυπουργός της Ελλάδας.\n",
        "assistant: B-PERSON I-PERSON E-PERSON O O B-LOC E-LOC O\n",
        "\"\"\"\n",
        "barziokas['llama_demo'] = [llama_prompt(text=t, instruction=instruction) for t in tqdm(barziokas.sentence.values)]"
      ],
      "metadata": {
        "id": "YRLYo2VUXCGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barziokas.llama_demo"
      ],
      "metadata": {
        "id": "qdQrJCQ4ZF2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "ner_labels = ['S-LOC', 'B-LOC', 'I-LOC', 'E-LOC', 'S-ORG', 'B-ORG', 'I-ORG', 'E-ORG', 'S-PERSON', 'B-PERSON', 'I-PERSON', 'E-PERSON', 'S-MISC', 'B-MISC', 'I-MISC', 'E-MISC', 'O']\n",
        "def extract_list(text, labels = ner_labels):\n",
        "  if isinstance(text, str):\n",
        "    text = text.strip().replace('\\n', '')\n",
        "    if '[' in text and ']' in text:\n",
        "      if ('\"' not in text) and (\"'\" not in text):\n",
        "        for label in labels:\n",
        "          text = text.replace(label, f'\"{label}\"')\n",
        "      text = text[text.index('[') : text.index(']')+1]\n",
        "    else:\n",
        "      text = text.split()\n",
        "    try:\n",
        "      text = ast.literal_eval(text)\n",
        "    except:\n",
        "      text = []\n",
        "  return text\n",
        "\n",
        "barziokas['llama_list'] = barziokas.llama_demo.fillna('[]').apply(extract_list)"
      ],
      "metadata": {
        "id": "1e_2G3i0YIL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = barziokas.apply(lambda row: row.llama_list[:len(row.ne_tag4)] + ['O' for _ in range(len(row.ne_tag4)-len(row.llama_list))], axis=1)\n",
        "gold = barziokas.ne_tag4\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(gold.explode(), predictions.explode(), labels=ner_labels, zero_division=0))"
      ],
      "metadata": {
        "id": "LoxHKRPhX2dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Original attempt"
      ],
      "metadata": {
        "id": "6QDNzkkOXsZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = '''\n",
        "Identify and label named entities in a given sentence using the specified NER tag set: `['S-LOC', 'O', 'B-ORG', 'E-ORG', 'B-PERSON', 'E-PERSON', 'I-ORG', 'B-LOC', 'E-LOC', 'S-PERSON', 'I-PERSON', 'S-ORG', 'S-MISC', 'B-MISC', 'I-MISC', 'E-MISC', 'I-LOC']`.\n",
        "You will be provided with a list of words, which form a sentence. Your task is to analyze this sentence and assign the appropriate named entity tag to each word.\n",
        "- For single-token entities, use the `S-` prefix followed by the appropriate entity type (e.g., `S-LOC` for a single-token location).\n",
        "- For multi-token entities, use the `B-`, `I-`, and `E-` prefixes to denote the beginning, inside, and end of the entity, respectively (e.g., `B-PERSON`, `I-PERSON`, `E-PERSON` for a person entity spanning multiple tokens).\n",
        "- Use the `O` tag for words that are not part of any named entity.\n",
        "Generate just a list with just the elements being the named entity tags corresponding to each word in the input list. Ensure that the tags correctly represent the boundaries and types of named entities as per the tag set provided.\n",
        "No text should be provided other than the list.\n",
        "\n",
        "Tag Set:\n",
        "    - `S-LOC`: Single-token location entity.\n",
        "    - `O`: Outside any named entity.\n",
        "    - `B-ORG`: Beginning of an organization entity.\n",
        "    - `E-ORG`: End of an organization entity.\n",
        "    - `B-PERSON`: Beginning of a person entity.\n",
        "    - `E-PERSON`: End of a person entity.\n",
        "    - `I-ORG`: Inside an organization entity.\n",
        "    - `B-LOC`: Beginning of a location entity.\n",
        "    - `E-LOC`: End of a location entity.\n",
        "    - `S-PERSON`: Single-token person entity.\n",
        "    - `I-PERSON`: Inside a person entity.\n",
        "    - `S-ORG`: Single-token organization entity.\n",
        "    - `S-MISC`: Single-token miscellaneous entity.\n",
        "    - `B-MISC`: Beginning of a miscellaneous entity.\n",
        "    - `I-MISC`: Inside a miscellaneous entity.\n",
        "    - `E-MISC`: End of a miscellaneous entity.\n",
        "    - `I-LOC`: Inside a location entity.\n",
        "'''\n",
        "barziokas['llama'] = [llama_prompt(text=t, instruction=instruction) for t in tqdm(barziokas.sentence.values)]"
      ],
      "metadata": {
        "id": "VxVIjvTokjpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barziokas.to_csv('barziokas.csv')\n",
        "#barziokas = pd.read_csv('barziokas.csv')"
      ],
      "metadata": {
        "id": "nphnmBuwuyzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "ner_labels = ['S-LOC', 'B-LOC', 'I-LOC', 'E-LOC', 'S-ORG', 'B-ORG', 'I-ORG', 'E-ORG', 'S-PERSON', 'B-PERSON', 'I-PERSON', 'E-PERSON', 'S-MISC', 'B-MISC', 'I-MISC', 'E-MISC', 'O']\n",
        "def extract_list(text, labels = ner_labels):\n",
        "  if isinstance(text, str):\n",
        "    text = text.strip().replace('\\n', '')\n",
        "    if '[' in text and ']' in text:\n",
        "      if ('\"' not in text) and (\"'\" not in text):\n",
        "        for label in labels:\n",
        "          text = text.replace(label, f'\"{label}\"')\n",
        "      text = text[text.index('[') : text.index(']')+1]\n",
        "    else:\n",
        "      text = '[]'\n",
        "    try:\n",
        "      text = ast.literal_eval(text)\n",
        "    except:\n",
        "      text = []\n",
        "  return text\n",
        "\n",
        "barziokas['llama_list'] = barziokas.llama.fillna('[]').apply(extract_list)"
      ],
      "metadata": {
        "id": "bYzxfq0YmS8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = barziokas.apply(lambda row: row.llama_list[:len(row.ne_tag4)] + ['O' for _ in range(len(row.ne_tag4)-len(row.llama_list))], axis=1)\n",
        "gold = barziokas.ne_tag4"
      ],
      "metadata": {
        "id": "Tzv-iBDXN7Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(gold.explode(), predictions.explode(), labels=ner_labels, zero_division=0))"
      ],
      "metadata": {
        "id": "NxGjoziOlnGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## POS"
      ],
      "metadata": {
        "id": "gBMh5tneqmq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prokopidis_ud = gena.ProkopidisUdDt( datasets=gr_data)\n",
        "prokopidis_ud.get('test').head()"
      ],
      "metadata": {
        "id": "tLZaEo_4qnU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=prokopidis_ud.get('test').x.unique()\n",
        "prokopidis_ud.get('test').x.value_counts()"
      ],
      "metadata": {
        "id": "MWP5zLMTGeqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prokopidis_ud.get('test').shape"
      ],
      "metadata": {
        "id": "Ar1E5vLlZXtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prokopidis_ud.get('test').x.value_counts().iloc[-1]/prokopidis_ud.get('test').x.value_counts().iloc[0]"
      ],
      "metadata": {
        "id": "l4AtERQjZrs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_level_pos = pd.DataFrame()\n",
        "text_level_pos['w'] = prokopidis_ud.get('test').groupby('s').w.apply(list)\n",
        "text_level_pos['x'] = prokopidis_ud.get('test').groupby('s').x.apply(list)\n",
        "text_level_pos.head()"
      ],
      "metadata": {
        "id": "NJcJ1gI2FETj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_level_pos.w.apply(len).describe()"
      ],
      "metadata": {
        "id": "GBDzLCXwY4qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: generate a prompt for llama for POS tagging, defining the following categories: 'NOUN', 'DET', 'PUNCT', 'VERB', 'ADJ', 'ADP', 'AUX', 'ADV', 'PRON', 'CCONJ', 'PROPN', '_', 'SCONJ', 'NUM', 'X', 'PART'. The input will already be tokenised to assist keeping the same length. Provide an explanation per named entity and provide a few examples.\n",
        "\n",
        "instruction = \"\"\"You are a Greek NLP expert and you are given a text that has already been tokenised. Return a sequence of Part-of-speech (POS) tags for each token in the text.\n",
        "The labels should be chosen from the following list: 'NOUN', 'DET', 'PUNCT', 'VERB', 'ADJ', 'ADP', 'AUX', 'ADV', 'PRON', 'CCONJ', 'PROPN', '_', 'SCONJ', 'NUM', 'X', 'PART'.\n",
        "Do not return any other text.\n",
        "\n",
        "**Explanation of POS Tags:**\n",
        "\n",
        "* **NOUN:** Noun (e.g., \"άνθρωπος\", \"πόλη\")\n",
        "* **DET:** Determiner (e.g., \"ο\", \"η\", \"το\")\n",
        "* **PUNCT:** Punctuation (e.g., \".\", \",\", \"!\")\n",
        "* **VERB:** Verb (e.g., \"γράφω\", \"τρώω\")\n",
        "* **ADJ:** Adjective (e.g., \"καλός\", \"μεγάλος\")\n",
        "* **ADP:** Adposition (prepositions and postpositions) (e.g., \"σε\", \"με\", \"από\")\n",
        "* **AUX:** Auxiliary verb (e.g., \"είμαι\", \"έχω\")\n",
        "* **ADV:** Adverb (e.g., \"γρήγορα\", \"πολύ\")\n",
        "* **PRON:** Pronoun (e.g., \"εγώ\", \"εσύ\", \"αυτός\")\n",
        "* **CCONJ:** Coordinating conjunction (e.g., \"και\", \"ή\")\n",
        "* **PROPN:** Proper noun (e.g., \"Αθήνα\", \"Γιώργος\")\n",
        "* **_:** Represents an unknown or missing tag.\n",
        "* **SCONJ:** Subordinating conjunction (e.g., \"ότι\", \"αν\")\n",
        "* **NUM:** Numeral (e.g., \"ένα\", \"δύο\")\n",
        "* **X:** Other (e.g., foreign words, abbreviations)\n",
        "* **PART:** Particle (e.g., \"να\", \"μη\")\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "* **Input:** [\"Ο\", \"Γιώργος\", \"γράφει\", \"ένα\", \"βιβλίο\", \".\"]\n",
        "* **Output:** ['DET', 'PROPN', 'VERB', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "* **Input:** [\"Η\", \"γρήγορη\", \"αλώπηκα\", \"τρέχει\", \".\"]\n",
        "* **Output:** ['DET', 'ADJ', 'NOUN', 'VERB', 'PUNCT']\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "text_level_pos['llama'] = [llama_prompt(text=t, instruction=instruction) for t in tqdm(text_level_pos.w.values)]"
      ],
      "metadata": {
        "id": "08CS0RhBW1aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_list(text, labels = labels):\n",
        "  \"\"\"\n",
        "  Extract a list from a string.\n",
        "  :param text: The string to extract the list from.\n",
        "  :param labels: The list of labels to use.\n",
        "  :return: The list extracted from the string.\n",
        "  \"\"\"\n",
        "  text = text.strip().replace('\"', '').replace('\\n', '').replace(\"'\", '')\n",
        "  text = text.replace('.', '').replace(',', '')\n",
        "  text = text.replace('[', '').replace(']', '')\n",
        "  casted_list = text.split()\n",
        "  if len(set(casted_list).intersection(set(labels)))==0:\n",
        "    return []\n",
        "  return casted_list\n",
        "\n",
        "text_level_pos['llama_post'] = text_level_pos['llama'].apply(lambda x: extract_list(x, labels=labels))"
      ],
      "metadata": {
        "id": "5jTHqYXRAEEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "predictions = text_level_pos.apply(lambda row: row.llama_post[:len(row.x)] + [np.random.choice(labels) for _ in range(len(row.x)-len(row.llama_post))], axis=1)\n",
        "gold = text_level_pos.x\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(gold.explode(), predictions.explode(), labels=labels, zero_division=0))"
      ],
      "metadata": {
        "id": "xMrbBRfFJNPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: generate a prompt for llama for POS tagging, defining the following categories: 'NOUN', 'DET', 'PUNCT', 'VERB', 'ADJ', 'ADP', 'AUX', 'ADV', 'PRON', 'CCONJ', 'PROPN', '_', 'SCONJ', 'NUM', 'X', 'PART'. The input will already be tokenised to assist keeping the same length. Provide an explanation per named entity and provide a few examples.\n",
        "\n",
        "instruction = \"\"\"You are a Greek NLP expert and you are given a text that has already been tokenised. Return a sequence of Part-of-speech (POS) tags for each token in the text.\n",
        "The labels should be chosen from the following list: 'NOUN', 'DET', 'PUNCT', 'VERB', 'ADJ', 'ADP', 'AUX', 'ADV', 'PRON', 'CCONJ', 'PROPN', '_', 'SCONJ', 'NUM', 'X', 'PART'.\n",
        "Do not return any other text.\n",
        "\n",
        "**Explanation of POS Tags:**\n",
        "\n",
        "* **NOUN:** Noun (e.g., \"άνθρωπος\", \"πόλη\")\n",
        "* **DET:** Determiner (e.g., \"ο\", \"η\", \"το\")\n",
        "* **PUNCT:** Punctuation (e.g., \".\", \",\", \"!\")\n",
        "* **VERB:** Verb (e.g., \"γράφω\", \"τρώω\")\n",
        "* **ADJ:** Adjective (e.g., \"καλός\", \"μεγάλος\")\n",
        "* **ADP:** Adposition (prepositions and postpositions) (e.g., \"σε\", \"με\", \"από\")\n",
        "* **AUX:** Auxiliary verb (e.g., \"είμαι\", \"έχω\")\n",
        "* **ADV:** Adverb (e.g., \"γρήγορα\", \"πολύ\")\n",
        "* **PRON:** Pronoun (e.g., \"εγώ\", \"εσύ\", \"αυτός\")\n",
        "* **CCONJ:** Coordinating conjunction (e.g., \"και\", \"ή\")\n",
        "* **PROPN:** Proper noun (e.g., \"Αθήνα\", \"Γιώργος\")\n",
        "* **_:** Represents an unknown or missing tag.\n",
        "* **SCONJ:** Subordinating conjunction (e.g., \"ότι\", \"αν\")\n",
        "* **NUM:** Numeral (e.g., \"ένα\", \"δύο\")\n",
        "* **X:** Other (e.g., foreign words, abbreviations)\n",
        "* **PART:** Particle (e.g., \"να\", \"μη\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "text_level_pos['llama0s'] = [llama_prompt(text=t, instruction=instruction) for t in tqdm(text_level_pos.w.values)]"
      ],
      "metadata": {
        "id": "qsM48HKP9s6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "text_level_pos['llama_post'] = text_level_pos['llama0s'].apply(lambda x: extract_list(x, labels=labels))\n",
        "predictions = text_level_pos.apply(lambda row: row.llama_post[:len(row.x)] + [np.random.choice(labels) for _ in range(len(row.x)-len(row.llama_post))], axis=1)\n",
        "gold = text_level_pos.x\n",
        "print(classification_report(gold.explode(), predictions.explode(), labels=labels, zero_division=0))"
      ],
      "metadata": {
        "id": "InN7kXDz-H62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(gold[:175].explode(), predictions[:175].explode(), labels=labels, zero_division=0))"
      ],
      "metadata": {
        "id": "-lQ3uCzdEfvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_level_pos.to_csv('pos-llama70b.csv')"
      ],
      "metadata": {
        "id": "Vc0BvSFMTD43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authorship analysis\n",
        "* Stdying whether LLMs encoded data from open books"
      ],
      "metadata": {
        "id": "yim6eMcMzLt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barzokas = gena.BarzokasDt(datasets=gr_data).get('train')\n",
        "barzokas.sample()"
      ],
      "metadata": {
        "id": "7BPbpX-WzM07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing duplicates\n",
        "print(barzokas.shape[0])\n",
        "print('Removing duplicates...')\n",
        "barzokas.drop_duplicates(inplace=True, subset=['text'])\n",
        "print(barzokas.shape[0])"
      ],
      "metadata": {
        "id": "m_ET-1UD2ZF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barzokas_df = barzokas[barzokas.status=='parsable']\n",
        "barzokas_df.shape"
      ],
      "metadata": {
        "id": "mwCCeOUB3Wve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need enough size to sample text from within\n",
        "barzokas_df.tokensCount.hist(bins=500, figsize=(8,2), log=True);"
      ],
      "metadata": {
        "id": "x5627Ae_ZMPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barzokas_df = barzokas_df[barzokas_df.tokensCount>1000]\n",
        "barzokas_df.shape"
      ],
      "metadata": {
        "id": "dpnjHaR_ZjHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling 1000 characters from the middle of the text\n",
        "def get_excerpt(text):\n",
        "  mid = len(text)/2\n",
        "  return text[int(mid-500):int(mid+500)]\n",
        "\n",
        "barzokas_df['excerpt'] = barzokas_df.text.apply(get_excerpt)"
      ],
      "metadata": {
        "id": "g-OkswZnwiOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barzokas_df[['id', 'title', 'excerpt', 'author', 'type', 'publishedYear', 'tokensCount']].to_csv('barzokas_excerpt.csv', index=False)"
      ],
      "metadata": {
        "id": "RWQzKBiyya2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pop_authors = barzokas_df.author.value_counts()[:17].index.tolist()\n",
        "barzokas_pop = barzokas_df[barzokas_df.author.isin(pop_authors)]\n",
        "print(barzokas_pop.shape)\n",
        "barzokas_pop.author.value_counts().plot.barh();"
      ],
      "metadata": {
        "id": "iF78l5Kl-NxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barzokas_pop.excerpt.apply(len).describe()"
      ],
      "metadata": {
        "id": "Imvuq4W4cM0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barzokas_pop.author.value_counts().iloc[-1]/barzokas_pop.author.value_counts().iloc[0]"
      ],
      "metadata": {
        "id": "26y-L4KVcjhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruct = \"Given an excerpt from a Greek book, return the author it is from by picking from the following authors: \" + ', '.join(pop_authors) +' Return only the name of the author, nothing else.'\n",
        "barzokas_pop['llama'] = [llama_prompt(text=t, instruction=instruct) for t in tqdm(barzokas_pop.excerpt.values)]"
      ],
      "metadata": {
        "id": "6ax_NEj3-DN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barzokas_pop['llama'] = barzokas_pop.llama.apply(lambda x: \"Θανάσης Τριαρίδης\" if \"ανάση\" in x else x)\n",
        "barzokas_pop['llama'] = barzokas_pop.llama.apply(lambda x: \"Plato\" if \"Plato\" in x else x)\n",
        "barzokas_pop['llama'] = barzokas_pop.llama.apply(lambda x: \"Κολιόπουλος\" if \"Κολιόπουλος\" in x else x)"
      ],
      "metadata": {
        "id": "J1Z5izhhAZVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "barzokas_pop_mini = barzokas_pop[:175]\n",
        "print(classification_report(barzokas_pop_mini.author, barzokas_pop_mini.llama.str.strip(), zero_division=0, labels=pop_authors))"
      ],
      "metadata": {
        "id": "oE3VPnEw_7E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(barzokas_pop_mini.author,\n",
        "                      barzokas_pop_mini.llama.str.strip(),\n",
        "                      labels=pop_authors)\n",
        "\n",
        "# Create a custom plot with Seaborn for better aesthetics\n",
        "plt.figure(figsize=(10, 8))  # Increase figure size for readability\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,  # Add annotations and color\n",
        "            xticklabels=pop_authors, yticklabels=pop_authors,\n",
        "            linewidths=0.5, linecolor='black', square=True)\n",
        "\n",
        "# Add labels, title, and customize ticks\n",
        "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
        "plt.ylabel(\"True Label\", fontsize=12)\n",
        "plt.title(\"Confusion Matrix\", fontsize=15)\n",
        "\n",
        "# Rotate x-axis labels for readability\n",
        "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "\n",
        "# Save the plot as a PDF with DPI=300\n",
        "plt.savefig(\"confusion_matrix.pdf\", format=\"pdf\", dpi=300, bbox_inches=\"tight\")\n",
        "\n",
        "# Show the plot (optional)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xf09Ll5vERK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barzokas_pop.to_csv('barzokas_pop_llama70b.csv')"
      ],
      "metadata": {
        "id": "PR7IE5fqEF1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Raw data analysis"
      ],
      "metadata": {
        "id": "Aoaoei2VzHia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title download the data\n",
        "raw_data = {}\n",
        "raw_data['prokopidis'] = gena.ProkopidisCrawledDt(datasets=gr_data).get('train')\n",
        "raw_data['dritsa'] = gena.DritsaDt(datasets=gr_data).get('train')\n",
        "raw_data['papantoniou'] = gena.PapantoniouDt(datasets=gr_data).get('train')"
      ],
      "metadata": {
        "id": "2q86BKNmTNib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Train a character-level language model per dataset.\n",
        "* Compute the BPC per dataset.\n",
        "* Draw a BPC heatmap, showing in red the dataset linguistically surprised by which."
      ],
      "metadata": {
        "id": "csU9FMpoml9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/ipavlopoulos/lm.git\n",
        "from lm.markov.models import LM\n",
        "\n",
        "train_sets = {}\n",
        "test_sets = {}\n",
        "for dataset_name in raw_data:\n",
        "  print(dataset_name)\n",
        "  dataset = raw_data[dataset_name]\n",
        "  dataset = dataset[dataset.text.notna()]\n",
        "  dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "  train_sets[dataset_name] = dataset.text.apply(lambda x: x[:100]).iloc[:1000] # lower lim\n",
        "  test_sets[dataset_name] = dataset.text.apply(lambda x: x[:100]).iloc[1000:1500]"
      ],
      "metadata": {
        "id": "Ffg204vJ4aic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Initialize dictionaries to store means and standard deviations\n",
        "ppls = {}\n",
        "ppls_sem = {}\n",
        "\n",
        "# Calculate means and standard deviations\n",
        "for dname in raw_data:\n",
        "    train = train_sets[dname]\n",
        "    test = test_sets[dname]\n",
        "    lm = LM(gram=\"CHAR\")\n",
        "    lm.train(' '.join(train.values)[:65000])  # length of min dataset\n",
        "    ppls[dname] = {}\n",
        "    ppls_sem[dname] = {}\n",
        "    for dname2 in raw_data:\n",
        "        scores = test_sets[dname2].apply(lm.bpc)\n",
        "        ppls[dname][dname2] = scores.mean()\n",
        "        ppls_sem[dname][dname2] = scores.sem()\n",
        "\n",
        "# Convert to DataFrames\n",
        "ppls_pd = pd.DataFrame(ppls)\n",
        "ppls_sem_pd = pd.DataFrame(ppls_std)\n",
        "\n",
        "# Create annotations with both mean and standard deviation\n",
        "annotations = ppls_pd.round(2).astype(str) + \" ± \" + ppls_sem_pd.round(2).astype(str)\n",
        "\n",
        "# Plot heatmap with annotations\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(ppls_pd, annot=annotations, fmt='', cmap=plt.cm.coolwarm, linewidths=0.5,\n",
        "            linecolor='black', cbar_kws={'label': 'BPC'})\n",
        "\n",
        "# Add labels and a title\n",
        "#plt.title('BPC per LM per dataset')\n",
        "plt.xlabel('Unseen text from'); plt.ylabel('LM trained on');\n",
        "plt.tight_layout();\n",
        "plt.savefig('ppl_heatmap.pdf', dpi=300, format='PDF')"
      ],
      "metadata": {
        "id": "PhiR2lIY4xgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Counting characters"
      ],
      "metadata": {
        "id": "DRc0QJ7vfJM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_num_all = 0\n",
        "for dataset_name in raw_data:\n",
        "  texts = raw_data[dataset_name][raw_data[dataset_name].text.notna()].text.values\n",
        "  tokens_num = sum([t.strip().count(' ')+1 for t in texts])\n",
        "  print(f'{dataset_name} ==> tokens: {tokens_num}')\n",
        "  tokens_num_all += tokens_num\n",
        "\n",
        "print(len(tokens_num_all))"
      ],
      "metadata": {
        "id": "gGXnhkVthgq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokens_num_all))"
      ],
      "metadata": {
        "id": "y-85aOpGvCxc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}